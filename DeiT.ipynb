{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "626fc3ada084434495066bbb6274607f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81ed5c294da74c52beb49287e8b3e974",
              "IPY_MODEL_7a61844773d347dd83408bcc5fa7f066",
              "IPY_MODEL_81db3ef4a97f4d9da5217883335ea3d5"
            ],
            "layout": "IPY_MODEL_064a7d1aeb054c1c95af20d9dd97cd49"
          }
        },
        "81ed5c294da74c52beb49287e8b3e974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbcd38933c68440c8073e6c5d7fe5a63",
            "placeholder": "​",
            "style": "IPY_MODEL_ae5fa274798847d3b7bf6a7771731023",
            "value": "model.safetensors: 100%"
          }
        },
        "7a61844773d347dd83408bcc5fa7f066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f687470721404d72bf577fb1575907a9",
            "max": 346284714,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_873a2c43bf5741948d47c8012a1134b4",
            "value": 346284714
          }
        },
        "81db3ef4a97f4d9da5217883335ea3d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6724419578842f2950b822f6ba024d1",
            "placeholder": "​",
            "style": "IPY_MODEL_51f6345cb7984efc95c7429ae87bdff9",
            "value": " 346M/346M [00:01&lt;00:00, 277MB/s]"
          }
        },
        "064a7d1aeb054c1c95af20d9dd97cd49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbcd38933c68440c8073e6c5d7fe5a63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae5fa274798847d3b7bf6a7771731023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f687470721404d72bf577fb1575907a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "873a2c43bf5741948d47c8012a1134b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6724419578842f2950b822f6ba024d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51f6345cb7984efc95c7429ae87bdff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_h6vhlGU8Hn",
        "outputId": "66a3e899-6e6d-409a-be87-1a8e95b00961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ComputerVisionProject' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/bakhbyergyen7/ComputerVisionProject.git\n",
        "# We might need to use this to load data since this is an image dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision\n",
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRBiBEtPWwKL",
        "outputId": "ad8a0456-760d-484a-85b7-80f60d137e44"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.2.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->torchvision) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1->torchvision) (1.3.0)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (0.9.16)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.17.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm) (12.4.127)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import timm\n",
        "from torchvision import transforms\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "Z4Tc2Tv0cqBi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Dataset loading\n",
        "def load_dataset(base_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for label_dir in os.listdir(base_dir):\n",
        "        emotion_dir = os.path.join(base_dir, label_dir)\n",
        "        if os.path.isdir(emotion_dir):\n",
        "            for img_file in os.listdir(emotion_dir):\n",
        "                img_path = os.path.join(emotion_dir, img_file)\n",
        "                images.append(img_path)\n",
        "                labels.append(label_dir)\n",
        "    return images, labels\n",
        "\n",
        "# Load and split dataset\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(*load_dataset('/content/ComputerVisionProject/project_1_dataset/train'), test_size=0.2, random_state=42)\n",
        "test_images, test_labels = load_dataset('/content/ComputerVisionProject/project_1_dataset/test')\n",
        "\n"
      ],
      "metadata": {
        "id": "i4NFGEh0sAhI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "train_encoded_labels = label_encoder.fit_transform(train_labels)\n",
        "val_encoded_labels = label_encoder.transform(val_labels)\n",
        "test_encoded_labels = label_encoder.transform(test_labels)"
      ],
      "metadata": {
        "id": "4KoiF4DnWhHx"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FacialExpressionDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label = torch.tensor(label, dtype=torch.long)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "PDpcAnitdNmC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = FacialExpressionDataset(train_images, train_encoded_labels, transform)\n",
        "val_dataset = FacialExpressionDataset(val_images, val_encoded_labels, transform)\n",
        "test_dataset = FacialExpressionDataset(test_images, test_encoded_labels, transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "AtoNReqJc3TZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load teacher and student models\n",
        "teacher_model = timm.create_model('deit_base_patch16_224', pretrained=True, num_classes=7)\n",
        "teacher_model.to(device)\n",
        "student_model = timm.create_model('deit_base_patch16_224', pretrained=True, num_classes=7)\n",
        "student_model.to(device)\n",
        "\n",
        "class DistillationLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.5, temperature=2.0):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "        self.KLDivLoss = nn.KLDivLoss(reduction='batchmean')\n",
        "        self.CELoss = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, student_output, labels, teacher_output):\n",
        "        soft_loss = self.KLDivLoss(\n",
        "            torch.log_softmax(student_output/self.temperature, dim=1),\n",
        "            torch.softmax(teacher_output/self.temperature, dim=1)\n",
        "        ) * (self.alpha * self.temperature * self.temperature)\n",
        "\n",
        "        hard_loss = self.CELoss(student_output, labels) * (1 - self.alpha)\n",
        "        return soft_loss + hard_loss\n",
        "\n",
        "criterion = DistillationLoss()\n",
        "optimizer = optim.Adam(student_model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "626fc3ada084434495066bbb6274607f",
            "81ed5c294da74c52beb49287e8b3e974",
            "7a61844773d347dd83408bcc5fa7f066",
            "81db3ef4a97f4d9da5217883335ea3d5",
            "064a7d1aeb054c1c95af20d9dd97cd49",
            "cbcd38933c68440c8073e6c5d7fe5a63",
            "ae5fa274798847d3b7bf6a7771731023",
            "f687470721404d72bf577fb1575907a9",
            "873a2c43bf5741948d47c8012a1134b4",
            "d6724419578842f2950b822f6ba024d1",
            "51f6345cb7984efc95c7429ae87bdff9"
          ]
        },
        "id": "-v0-VyQYiApA",
        "outputId": "1ca89e39-50ff-40e3-8a3d-d1a297b72a84"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "626fc3ada084434495066bbb6274607f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, path):\n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "def load_model(model, path):\n",
        "    model.load_state_dict(torch.load(path))\n",
        "    return model\n",
        "\n",
        "# Evaluate model function\n",
        "def evaluate_model(model, loader, criterion, teacher_model=None):\n",
        "    model.eval()\n",
        "    if teacher_model:\n",
        "        teacher_model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            if teacher_model:\n",
        "                teacher_outputs = teacher_model(images)\n",
        "                loss = criterion(outputs, labels, teacher_outputs)\n",
        "            else:\n",
        "                # Fallback if no teacher model provided\n",
        "                loss = criterion(outputs, labels, outputs)\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "            total += labels.size(0)\n",
        "            all_preds.extend(preds.view(-1).cpu().numpy())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = running_corrects.double() / total\n",
        "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "    return epoch_loss, epoch_acc, conf_matrix"
      ],
      "metadata": {
        "id": "zGX1bQBip-xK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(teacher_model, student_model, criterion, optimizer, scheduler, train_loader, val_loader, epochs=250, patience=20):\n",
        "    best_val_loss = float('inf')\n",
        "    no_improve_epochs = 0\n",
        "    train_acc_history = []\n",
        "    val_acc_history = []\n",
        "    train_loss_history = []\n",
        "    val_loss_history = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        student_model.train()\n",
        "        train_loss = 0.0\n",
        "        train_corrects = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            # Forward pass through the teacher model\n",
        "            with torch.no_grad():\n",
        "                teacher_outputs = teacher_model(images)\n",
        "\n",
        "            # Forward pass through the student model\n",
        "            student_outputs = student_model(images)\n",
        "            loss = criterion(student_outputs, labels, teacher_outputs)\n",
        "\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, preds = torch.max(student_outputs, 1)\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "            train_corrects += torch.sum(preds == labels.data)\n",
        "            train_total += labels.size(0)\n",
        "\n",
        "        train_epoch_loss = train_loss / train_total\n",
        "        train_epoch_acc = train_corrects.double() / train_total\n",
        "        train_acc_history.append(train_epoch_acc.item())\n",
        "        train_loss_history.append(train_epoch_loss)\n",
        "\n",
        "        # Validation phase\n",
        "        val_epoch_loss, val_epoch_acc, _ = evaluate_model(student_model, val_loader, criterion, teacher_model)\n",
        "        val_acc_history.append(val_epoch_acc.item())\n",
        "        val_loss_history.append(val_epoch_loss)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{epochs} - Train Loss: {train_epoch_loss:.4f}, Acc: {train_epoch_acc:.4f}')\n",
        "        print(f'Validation Loss: {val_epoch_loss:.4f}, Acc: {val_epoch_acc:.4f}')\n",
        "\n",
        "        if val_epoch_loss < best_val_loss:\n",
        "            best_val_loss = val_epoch_loss\n",
        "            no_improve_epochs = 0\n",
        "            save_model(student_model, '/home/yuying/841/deit_distilled_model.pth')\n",
        "            print('Model saved')\n",
        "        else:\n",
        "            no_improve_epochs += 1\n",
        "            if no_improve_epochs >= patience:\n",
        "                print('Early stopping triggered due to no improvement.')\n",
        "                break\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Plotting accuracy and loss\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(range(1, len(train_acc_history)+1), train_acc_history, label='Train Accuracy')\n",
        "    plt.plot(range(1, len(val_acc_history)+1), val_acc_history, label='Validation Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(range(1, len(train_loss_history)+1), train_loss_history, label='Train Loss')\n",
        "    plt.plot(range(1, len(val_loss_history)+1), val_loss_history, label='Validation Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig('/home/yuying/841/final_deit_results.png')\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "oFjy5TUZqC6a"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, loader, criterion):\n",
        "    test_loss, test_accuracy, test_conf_matrix = evaluate_model(model, loader, criterion)\n",
        "    print(f'Test Loss: {test_loss:.4f}')\n",
        "    print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "    print(f'Test Confusion Matrix:\\n{test_conf_matrix}')\n",
        "    return test_accuracy, test_conf_matrix\n"
      ],
      "metadata": {
        "id": "ARNiNv70qFcI"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mode = 'test'  # Options: 'train', 'test', 'both'\n",
        "\n",
        "if mode == 'train' or mode == 'both':\n",
        "    trained_student_model = train_model(teacher_model, student_model, criterion, optimizer, scheduler, train_loader, val_loader)\n",
        "    print(\"Training completed.\")\n",
        "\n",
        "if mode == 'test' or mode == 'both':\n",
        "    student_model = load_model(student_model, '/content/deit_distilled_model.pth')\n",
        "    test_accuracy, test_conf_matrix = test_model(student_model, test_loader, criterion)\n",
        "    print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "    print(f'Test Confusion Matrix:\\n{test_conf_matrix}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNAGAv6JstHN",
        "outputId": "4c1d4c67-adc8-4656-b454-f86a28fe8567"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.6578\n",
            "Test Accuracy: 0.7016\n",
            "Test Confusion Matrix:\n",
            "[[ 411    1   51   17   81  146   20]\n",
            " [  17   40    1    2    4   14    0]\n",
            " [  60    2  323   19   63  174   80]\n",
            " [  15    0    6 1200   63   43   21]\n",
            " [  37    0   32   35  677  174    7]\n",
            " [  56    2   52   11  120  494    6]\n",
            " [   6    1   37   15   11   36  472]]\n",
            "Test Accuracy: 0.7016\n",
            "Test Confusion Matrix:\n",
            "[[ 411    1   51   17   81  146   20]\n",
            " [  17   40    1    2    4   14    0]\n",
            " [  60    2  323   19   63  174   80]\n",
            " [  15    0    6 1200   63   43   21]\n",
            " [  37    0   32   35  677  174    7]\n",
            " [  56    2   52   11  120  494    6]\n",
            " [   6    1   37   15   11   36  472]]\n"
          ]
        }
      ]
    }
  ]
}